---
layout: default
title: Hyeonseob Nam
---

## About Me

<img class="profile-picture" src="hsnam.png">

I am a research scientist at [Lunit](https://lunit.io/?lang=en), working on deep learning with medical images.
I received my B.S. and M.S. degrees in Computer Science and Engineering from [POSTECH](http://www.postech.ac.kr/eng/), advised by Prof. [Bohyung Han](https://cv.snu.ac.kr/index.php/~bhhan/), where I pioneered the intersection of deep learning and visual tracking.
Before joining Lunit, I worked as a machine learning engineer at [NAVER](https://www.navercorp.com/en).
My research interests include computer vision and deep learning with particular focus on multi-domain problems and robustness in real-world scenarios.

## Education

- **M.S.** in Computer Science and Engineering, [Computer Vision Lab](http://cvlab.postech.ac.kr/lab/), [POSTECH](http://www.postech.ac.kr/eng/) (Sept. 2013 - Feb. 2016)
- **B.S.** in Computer Science and Engineering (*summa cum laude*), [POSTECH](http://www.postech.ac.kr/eng/) (Mar. 2009 - Aug. 2013)

## Work Experience 

- **Research Scientist**, [Lunit](https://lunit.io/?lang=en) (Dec. 2017 - Current)
- **Research Engineer**, [NAVER](https://www.navercorp.com/en) (Mar. 2016 - Nov. 2017)

## Selected Publications

- <span class="paper-title">[Reducing Domain Gap by Reducing Style Bias](https://arxiv.org/pdf/1910.11645.pdf)</span><br />
  **Hyeonseob Nam**\*, HyunJae Lee\*, Jongchan Park, Wonjun Yoon, Donggeun Yoo (\* equal contribution)<br />
  IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2017 (**Oral**)<br />
  **1st place in VisDA-2019 challenge**<br />
  [[code](https://github.com/hyeonseobnam/style-agnostic-networks)]

- <span class="paper-title">[SRM: A Style-based Recalibration Module for Convolutional Neural Networks](https://arxiv.org/pdf/1903.10829.pdf)</span><br />
  HyunJae Lee, Hyo-Eun Kim, **Hyeonseob Nam**<br />
  IEEE International Conference on Computer Vision (**ICCV**), 2019<br />
  [[code](https://github.com/hyunjaelee410/style-based-recalibration-module)]

- <span class="paper-title">[Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks](https://arxiv.org/pdf/1805.07925.pdf)</span><br />
  **Hyeonseob Nam**, Hyo-Eun Kim<br />
  Conference on Neural Information Processing Systems (**NeurIPS**), 2018<br />
  [[code](https://github.com/hyeonseob-nam/Batch-Instance-Normalization)]

- <span class="paper-title">[Dual Attention Networks for Multimodal Reasoning and Matching](https://arxiv.org/pdf/1611.00471.pdf)</span><br />
  **Hyeonseob Nam**, Jung-Woo Ha, Jeonghee Kim<br />
  IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2017 (**Spotlight**)<br />
  **2nd place in VQA-2016 challenge**

- <span class="paper-title">[Modeling and Propagating CNNs in a Tree Structure for Visual Tracking](https://arxiv.org/pdf/1608.07242.pdf)</span><br />
  **Hyeonseob Nam**\*, Mooyeol Baek\*, Bohyung Han (\* equal contribution)<br />
  Tech report, arXiv, 2016<br />
  **1st place in VOT-2016 challenge**
  
- <span class="paper-title">[Learning Multi-Domain Convolutional Neural Networks for Visual Tracking](https://arxiv.org/pdf/1510.07945.pdf)</span><br />
  **Hyeonseob Nam**, Bohyung Han<br />
  IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2016<br />
  **1st place in VOT-2015 challenge**<br />
  [[project](http://cvlab.postech.ac.kr/research/mdnet/)]
  [[code-matlab](https://github.com/hyeonseobnam/MDNet)]
  [[code-python](https://github.com/hyeonseobnam/py-MDNet)]

- <span class="paper-title">[Online Graph-based Tracking](http://cvlab.postech.ac.kr/~maga33/eccv2014_OGT.pdf)</span><br />
  **Hyeonseob Nam**, Seunghoon Hong, Bohyung Han<br />
  European Conference on Computer Vision (**ECCV**), 2014<br />
  [[project](http://cvlab.postech.ac.kr/research/beyondchainmodels/)]


## Invited Talks
- [Kakao Brain](https://www.kakaobrain.com/), "Towards Robust AI against Image Style Variability", 2021
- [ICCV Workshop (VRMI)](https://sites.google.com/view/iccv19-vrmi), "Towards Overcoming Style Variability in Medical Images", 2019
- [LG CNS](https://www.lgcns.com/En/Home), "Deep Learning for Medical Image Analysis", 2018
- [SK T-Brain](https://www.skt.ai/index.do), "Dual Attention Networks for Multimodal Reasoning and Matching", 2016
- [StradVision](https://stradvision.com/), "Deep Learning for Visual Tracking", 2016
- [NAVER LABS](https://www.naverlabs.com/en/), "Deep Learning for Visual Tracking", 2015


## Challenge Awards

- ***Winner***, [Visual Domain Adaptation (VisDA) Challenge](http://ai.bu.edu/visda-2019/), ICCV Workshop, 2019<br />
  **Hyeonseob Nam**, HyunJae Lee, Jongchan Park, Wonjun Yoon, Donggeun Yoo
- ***Runner-up***, [Visual Question Answering (VQA) Challenge](https://visualqa.org/challenge_2016.html), CVPR Workshop, 2016<br />
  **Hyeonseob Nam**, Jeonghee Kim
- ***Winner***, [Visual Object Tracking (VOT) Challenge](http://www.votchallenge.net/vot2016/), ECCV Workshop, 2016<br />
  **Hyeonseob Nam**\*, Mooyeol Baek\*, Bohyung Han (\* equal contribution)
- ***Winner***, [Visual Object Tracking (VOT) Challenge](http://www.votchallenge.net/vot2015/), ICCV Workshop, 2015<br />
  **Hyeonseob Nam**, Bohyung Han
